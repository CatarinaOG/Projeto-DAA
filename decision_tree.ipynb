{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"training_data.csv\")\n",
    "test_data = pd.read_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como as colunas city_name e avg_precipitation possuem apenas 1 valor, podemos retirá-las, já que não vão ter nenhuma influência na previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique()\n",
    "\n",
    "\n",
    "\n",
    "data2 = data.drop(['city_name', 'avg_precipitation'], axis=1)\n",
    "test_data2 = test_data.drop(['city_name', 'avg_precipitation'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data2.isnull(), yticklabels=False, cbar=False, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(test_data2.isnull(), yticklabels=False, cbar=False, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "data_roads = data2.copy()\n",
    "\n",
    "#print(data2['affected_roads']).head(30)\n",
    "all_roads = {}\n",
    "for road_list in data_roads['affected_roads']:\n",
    "    if type(road_list) == type(float(i)):\n",
    "        #print(\"Iteração ::\", i)\n",
    "        data_roads.at[i, 'affected_roads'] = \",\"\n",
    "    else: \n",
    "        road_list = str(road_list)\n",
    "        if road_list != \",\":\n",
    "            roads = road_list.split(\",\")\n",
    "            #print(roads)\n",
    "            dic = {}\n",
    "            \n",
    "            for road in roads:\n",
    "                #print(road)\n",
    "                if road not in dic and road != \"\":\n",
    "                    #print(road)\n",
    "                    dic[road] = 0\n",
    "                if road not in all_roads and road != \"\":\n",
    "                    all_roads[road] = 0\n",
    "            #data2['affected_roads'][i] = str(list(dic.keys()))\n",
    "            data_roads.at[i, 'affected_roads'] = list(dic.keys())\n",
    "            #print(list(dic.keys()))\n",
    "    i = i + 1\n",
    "print(\"Nº de estradas :: \", len(all_roads))\n",
    "print(\"Estradas :: \", list(all_roads.keys()))\n",
    "\n",
    "\n",
    "i = 0\n",
    "\n",
    "test_data_roads = test_data2.copy()\n",
    "\n",
    "#print(data2['affected_roads']).head(30)\n",
    "all_roads_test = {}\n",
    "for road_list in test_data_roads['affected_roads']:\n",
    "    if type(road_list) == type(float(i)):\n",
    "        #print(\"Iteração ::\", i)\n",
    "        test_data_roads.at[i, 'affected_roads'] = \",\"\n",
    "    else: \n",
    "        road_list = str(road_list)\n",
    "        if road_list != \",\":\n",
    "            roads = road_list.split(\",\")\n",
    "            #print(roads)\n",
    "            dic = {}\n",
    "            \n",
    "            for road in roads:\n",
    "                #print(road)\n",
    "                if road not in dic and road != \"\":\n",
    "                    #print(road)\n",
    "                    dic[road] = 0\n",
    "                if road not in all_roads_test and road != \"\":\n",
    "                    all_roads_test[road] = 0\n",
    "            #data2['affected_roads'][i] = str(list(dic.keys()))\n",
    "            test_data_roads.at[i, 'affected_roads'] = list(dic.keys())\n",
    "            #print(list(dic.keys()))\n",
    "    i = i + 1\n",
    "print(\"Nº de estradas :: \", len(all_roads_test))\n",
    "print(\"Estradas :: \", list(all_roads_test.keys()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_roads.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for road in all_roads:\n",
    "    data_roads[road] = 0\n",
    "\n",
    "for road in all_roads_test:\n",
    "    test_data_roads[road] = 0\n",
    "#data2.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_roads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for reg in data_roads:\n",
    "    list = data_roads.at[i, 'affected_roads']\n",
    "    for road in list:\n",
    "        if road != \",\":\n",
    "            data_roads.at[i, road] = 1\n",
    "    i = i + 1\n",
    "\n",
    "\n",
    "i = 0\n",
    "for reg in test_data_roads:\n",
    "    list = test_data_roads.at[i, 'affected_roads']\n",
    "    for road in list:\n",
    "        if road != \",\":\n",
    "            test_data_roads.at[i, road] = 1\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data_roads.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data_roads.dropna()\n",
    "sns.heatmap(data_roads.isnull(), yticklabels=False, cbar=False, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como os valores dos incidentes, a nossa label, são categóricos, estes não poderão ser submetidos à maioria dos modelos de ML disponíveis. Assim, teremos de convertê-los para valores numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_map = {'incidents' : {'None': 0, 'Low': 1, 'Medium': 2, 'High': 3, 'Very_High':4}}\n",
    "\n",
    "data4 = data3.replace(replace_map)\n",
    "data4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, agora o tipo do feature Incidents é numérico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos tratar das datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4['record_date'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4['record_date'] = pd.to_datetime(data4['record_date'], format = \"%Y-%m-%d %H:%M\", errors='coerce')\n",
    "assert data4['record_date'].isnull().sum() == 0, 'missing record date'\n",
    "data4['record_date'].head()\n",
    "\n",
    "test_data_roads['record_date'] = pd.to_datetime(test_data_roads['record_date'], format = \"%Y-%m-%d %H:%M\", errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4['record_date_year'] = data4['record_date'].dt.year\n",
    "data4['record_date_month'] = data4['record_date'].dt.month\n",
    "data4['record_date_day'] = data4['record_date'].dt.day\n",
    "data4['record_date_hour'] = data4['record_date'].dt.hour\n",
    "data4['record_date_minute'] = data4['record_date'].dt.minute\n",
    "\n",
    "test_data_roads['record_date_year'] = test_data_roads['record_date'].dt.year\n",
    "test_data_roads['record_date_month'] = test_data_roads['record_date'].dt.month\n",
    "test_data_roads['record_date_day'] = test_data_roads['record_date'].dt.day\n",
    "test_data_roads['record_date_hour'] = test_data_roads['record_date'].dt.hour\n",
    "test_data_roads['record_date_minute'] = test_data_roads['record_date'].dt.minute\n",
    "\n",
    "\n",
    "data4.head()\n",
    "test_data_roads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui podemos verificar que o ano dos incidentes, bem como o minuto, são features com um único valor, sendo então essa informação inútil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5 = data4.drop(['record_date_minute','record_date_year', 'record_date', 'affected_roads'], axis = 1)\n",
    "test_data3 = test_data_roads.drop(['record_date_minute','record_date_year', 'record_date', 'affected_roads'], axis = 1)\n",
    "print(data5['magnitude_of_delay'].unique())\n",
    "print(data5['luminosity'].unique())\n",
    "print(data5['avg_rain'].unique())\n",
    "#data5.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 'magnitude_of_delay' tem 3 valores possíveis: UNDEFINED, MAJOR e MODERATE <br>\n",
    "A luminosidade tem 3 valores possíveis: LIGHT, LOW_LIGHT, DARK <br>\n",
    "A 'avg_rain' tem 4 valores possíveis: Sem Chuva, chuva moderada, chuva fraca, chuva forte <br>\n",
    "Assim, teremos de transformar estes valores em valores numéricos, fazendo label enconding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_map = { 'magnitude_of_delay' : {'UNDEFINED': 0, 'MODERATE': 1, 'MAJOR': 2}, \n",
    "                'luminosity': {'DARK': 0, 'LIGHT': 1, 'LOW_LIGHT': 2},\n",
    "                'avg_rain': {'Sem Chuva': 0, 'chuva moderada': 1, 'chuva fraca': 2, 'chuva forte': 3}\n",
    "              }\n",
    "data6 = data5.replace(replace_map)\n",
    "test_data4 = test_data3.replace(replace_map)\n",
    "\n",
    "data6.head()\n",
    "test_data4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois de feita toda a etapa de feature engineering, vamos agora construir um modelo de regressão logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data6\n",
    "df_test = test_data4\n",
    "\n",
    "X = df.drop('incidents', axis=1)\n",
    "y = df['incidents']\n",
    "X_test = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dt = clf.predict(X_test)\n",
    "predictions_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace_map = {'incidents' : {'None': 0, 'Low': 1, 'Medium': 2, 'High': 3, 'Very_High':4}}\n",
    "\n",
    "outcome = []\n",
    "for i in range(len(predictions_dt)):\n",
    "    if predictions_dt[i] == 0:\n",
    "        outcome.append({'RowId' : i+1 , 'Incidents' : 'None'})\n",
    "    elif predictions_dt[i] == 1:\n",
    "        outcome.append({'RowId' : i+1 , 'Incidents' : 'Low'})\n",
    "    elif predictions_dt[i] == 2:\n",
    "        outcome.append({'RowId' : i+1 , 'Incidents' : 'Medium'})\n",
    "    elif predictions_dt[i] == 3:\n",
    "        outcome.append({'RowId' : i+1 , 'Incidents' : 'High'})\n",
    "    elif predictions_dt[i] == 4:\n",
    "        outcome.append({'RowId' : i+1 , 'Incidents' : 'Very_High'})\n",
    "    \n",
    "print(outcome)\n",
    "od = pd.DataFrame(outcome)\n",
    "od.to_csv(\"out_file.csv\", index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('daa2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "04ad44b987751ab7a9995291660dd07bc8c754e2ae0d797f637fc42681b84743"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
