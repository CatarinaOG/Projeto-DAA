{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"training_data.csv\")\n",
    "test_data = pd.read_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como as colunas city_name e avg_precipitation possuem apenas 1 valor, podemos retirá-las, já que não vão ter nenhuma influência na previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique()\n",
    "\n",
    "data2 = data.drop(['city_name', 'avg_precipitation'], axis=1)\n",
    "test_data2 = test_data.drop(['city_name', 'avg_precipitation'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data2.isnull(), yticklabels=False, cbar=False, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(test_data2.isnull(), yticklabels=False, cbar=False, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "data_roads = data2.copy()\n",
    "\n",
    "#print(data2['affected_roads']).head(30)\n",
    "all_roads = {}\n",
    "for road_list in data_roads['affected_roads']:\n",
    "    if type(road_list) == type(float(i)):\n",
    "        #print(\"Iteração ::\", i)\n",
    "        data_roads.at[i, 'affected_roads'] = \",\"\n",
    "    else: \n",
    "        road_list = str(road_list)\n",
    "        if road_list != \",\":\n",
    "            roads = road_list.split(\",\")\n",
    "            #print(roads)\n",
    "            dic = {}\n",
    "            \n",
    "            for road in roads:\n",
    "                #print(road)\n",
    "                if road not in dic and road != \"\":\n",
    "                    #print(road)\n",
    "                    dic[road] = 0\n",
    "                if road not in all_roads and road != \"\":\n",
    "                    all_roads[road] = 0\n",
    "            #data2['affected_roads'][i] = str(list(dic.keys()))\n",
    "            data_roads.at[i, 'affected_roads'] = dic.keys()\n",
    "            #print(list(dic.keys()))\n",
    "    i = i + 1\n",
    "print(\"Nº de estradas :: \", len(all_roads))\n",
    "print(\"Estradas :: \", all_roads.keys())\n",
    "\n",
    "\n",
    "i = 0\n",
    "\n",
    "test_data_roads = test_data2.copy()\n",
    "\n",
    "#print(data2['affected_roads']).head(30)\n",
    "all_roads_test = {}\n",
    "for road_list in test_data_roads['affected_roads']:\n",
    "    if type(road_list) == type(float(i)):\n",
    "        #print(\"Iteração ::\", i)\n",
    "        test_data_roads.at[i, 'affected_roads'] = \",\"\n",
    "    else: \n",
    "        road_list = str(road_list)\n",
    "        if road_list != \",\":\n",
    "            roads = road_list.split(\",\")\n",
    "            #print(roads)\n",
    "            dic = {}\n",
    "            \n",
    "            for road in roads:\n",
    "                #print(road)\n",
    "                if road not in dic and road != \"\":\n",
    "                    #print(road)\n",
    "                    dic[road] = 0\n",
    "                if road not in all_roads_test and road != \"\":\n",
    "                    all_roads_test[road] = 0\n",
    "            #data2['affected_roads'][i] = str(list(dic.keys()))\n",
    "            test_data_roads.at[i, 'affected_roads'] = dic.keys()\n",
    "            #print(list(dic.keys()))\n",
    "    i = i + 1\n",
    "print(\"Nº de estradas :: \", len(all_roads_test))\n",
    "print(\"Estradas :: \", all_roads_test.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_roads.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_roads_list = sorted(all_roads.keys())\n",
    "\n",
    "for road in all_roads_list:\n",
    "    data_roads[road] = 0\n",
    "\n",
    "data_roads['others'] = 0\n",
    "\n",
    "all_roads_test_list = sorted(all_roads.keys())\n",
    "for road in all_roads_test_list:\n",
    "    if road in all_roads_list:\n",
    "        test_data_roads[road] = 0\n",
    "\n",
    "test_data_roads['others'] = 0\n",
    "#data2.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_roads.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_roads.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for reg in data_roads:\n",
    "    list = data_roads.at[i, 'affected_roads']\n",
    "    for road in list:\n",
    "        if road != \",\":\n",
    "            data_roads.at[i, road] = 1\n",
    "    i = i + 1\n",
    "\n",
    "\n",
    "i = 0\n",
    "for reg in test_data_roads:\n",
    "    list = test_data_roads.at[i, 'affected_roads']\n",
    "    for road in list:\n",
    "        if road != \",\":\n",
    "            if road not in all_roads.keys():\n",
    "                test_data_roads.at[i,'others'] = 1\n",
    "            else:\n",
    "                test_data_roads.at[i, road] = 1\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data_roads.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data_roads.dropna()\n",
    "sns.heatmap(data_roads.isnull(), yticklabels=False, cbar=False, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como os valores dos incidentes, a nossa label, são categóricos, estes não poderão ser submetidos à maioria dos modelos de ML disponíveis. Assim, teremos de convertê-los para valores numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_map = {'incidents' : {'None': 0, 'Low': 1, 'Medium': 2, 'High': 3, 'Very_High':4}}\n",
    "\n",
    "data4 = data3.replace(replace_map)\n",
    "data4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, agora o tipo do feature Incidents é numérico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos tratar das datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4['record_date'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4['record_date'] = pd.to_datetime(data4['record_date'], format = \"%Y-%m-%d %H:%M\", errors='coerce')\n",
    "assert data4['record_date'].isnull().sum() == 0, 'missing record date'\n",
    "data4['record_date'].head()\n",
    "\n",
    "test_data_roads['record_date'] = pd.to_datetime(test_data_roads['record_date'], format = \"%Y-%m-%d %H:%M\", errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4['record_date_year'] = data4['record_date'].dt.year\n",
    "data4['record_date_month'] = data4['record_date'].dt.month\n",
    "data4['record_date_day'] = data4['record_date'].dt.day\n",
    "data4['record_date_hour'] = data4['record_date'].dt.hour\n",
    "data4['record_date_minute'] = data4['record_date'].dt.minute\n",
    "\n",
    "test_data_roads['record_date_year'] = test_data_roads['record_date'].dt.year\n",
    "test_data_roads['record_date_month'] = test_data_roads['record_date'].dt.month\n",
    "test_data_roads['record_date_day'] = test_data_roads['record_date'].dt.day\n",
    "test_data_roads['record_date_hour'] = test_data_roads['record_date'].dt.hour\n",
    "test_data_roads['record_date_minute'] = test_data_roads['record_date'].dt.minute\n",
    "\n",
    "\n",
    "data4.head()\n",
    "test_data_roads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data4.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui podemos verificar que o ano dos incidentes, bem como o minuto, são features com um único valor, sendo então essa informação inútil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5 = data4.drop(['record_date_minute','record_date_year','affected_roads'], axis = 1)\n",
    "test_data3 = test_data_roads.drop(['record_date_minute','record_date_year','affected_roads'], axis = 1)\n",
    "print(data5['magnitude_of_delay'].unique())\n",
    "print(data5['luminosity'].unique())\n",
    "print(data5['avg_rain'].unique())\n",
    "data5.info()\n",
    "test_data3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 'magnitude_of_delay' tem 3 valores possíveis: UNDEFINED, MAJOR e MODERATE <br>\n",
    "A luminosidade tem 3 valores possíveis: LIGHT, LOW_LIGHT, DARK <br>\n",
    "A 'avg_rain' tem 4 valores possíveis: Sem Chuva, chuva moderada, chuva fraca, chuva forte <br>\n",
    "Assim, teremos de transformar estes valores em valores numéricos, fazendo label enconding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_and_bind(original_dataframe, feature_to_encode):\n",
    "    dummies = pd.get_dummies(original_dataframe[[feature_to_encode]])\n",
    "    res = pd.concat([original_dataframe, dummies], axis=1)\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data6 = encode_and_bind(data5, 'magnitude_of_delay')\n",
    "data6.drop('magnitude_of_delay',axis=1, inplace=True)\n",
    "\n",
    "data7 = encode_and_bind(data6, 'luminosity')\n",
    "data7.drop('luminosity',axis=1, inplace=True)\n",
    "\n",
    "data8 = encode_and_bind(data7, 'avg_rain')\n",
    "data8.drop('avg_rain', axis=1, inplace=True)\n",
    "\n",
    "test_data4 = encode_and_bind(test_data3, 'magnitude_of_delay')\n",
    "test_data4.drop('magnitude_of_delay',axis=1, inplace=True)\n",
    "\n",
    "test_data5 = encode_and_bind(test_data4, 'luminosity')\n",
    "test_data5.drop('luminosity',axis=1, inplace=True)\n",
    "\n",
    "test_data6 = encode_and_bind(test_data5, 'avg_rain')\n",
    "test_data6.drop('avg_rain',axis=1, inplace=True)\n",
    "\n",
    "data_ohe = data8\n",
    "data_ohe.head()\n",
    "\n",
    "test_ohe = test_data6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduzir as estações do ano como uma feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data7 = data6\n",
    "data7['season'] = 0\n",
    "test_data5 = test_data4\n",
    "test_data5['season'] = 0\n",
    "\n",
    "for i in data7.index:\n",
    "    if data7.at[i, 'record_date_month'] in [1, 2,3]:\n",
    "        data7.at[i, 'season'] = 1 # Winter\n",
    "    elif data7.at[i, 'record_date_month'] in [4, 5, 6]:\n",
    "        data7.at[i, 'season'] = 2 # Spring\n",
    "    elif data7.at[i, 'record_date_month'] in [7, 8, 9]:\n",
    "        data7.at[i, 'season'] = 3 # Summer\n",
    "    elif data7.at[i, 'record_date_month'] in [10, 11, 12]:\n",
    "        data7.at[i, 'season'] = 4 # Fall\n",
    "\n",
    "for i in test_data5.index:\n",
    "    if test_data5.at[i, 'record_date_month'] in [1, 2,3]:\n",
    "        test_data5.at[i, 'season'] = 1 # Winter\n",
    "    elif test_data5.at[i, 'record_date_month'] in [4, 5, 6]:\n",
    "        test_data5.at[i, 'season'] = 2 # Spring\n",
    "    elif test_data5.at[i, 'record_date_month'] in [7, 8, 9]:\n",
    "        test_data5.at[i, 'season'] = 3 # Summer\n",
    "    elif test_data5.at[i, 'record_date_month'] in [10, 11, 12]:\n",
    "        test_data5.at[i, 'season'] = 4 # Fall"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois de feita toda a etapa de feature engineering, vamos agora construir um modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data8 = data_ohe.copy()\n",
    "data8['date_offset'] = (data8['record_date'].dt.month*100 + data8['record_date'].dt.day - 320)%1300\n",
    "\n",
    "data8['season'] = pd.cut(data8['date_offset'], [0, 300, 602, 900, 1300], \n",
    "                      labels = ['spring', 'summer', 'autumn', 'winter'], include_lowest=True)\n",
    "data8.drop(['date_offset', 'record_date'], axis = 1, inplace=True)\n",
    "replace_map = { 'season' : {'spring': 1, 'summer': 2, 'autumn': 3, 'winter' : 4}}\n",
    "data9 = data8.replace(replace_map)\n",
    "data9['season'] = data9['season'].astype(int)\n",
    "\n",
    "data_season = data9\n",
    "\n",
    "\n",
    "test_data6 = test_ohe.copy()\n",
    "test_data6['date_offset'] = (test_data6['record_date'].dt.month*100 + test_data6['record_date'].dt.day - 320)%1300\n",
    "\n",
    "test_data6['season'] = pd.cut(test_data6['date_offset'], [0, 300, 602, 900, 1300], \n",
    "                      labels = ['spring', 'summer', 'autumn', 'winter'], include_lowest=True)\n",
    "test_data6.drop(['date_offset', 'record_date'], axis = 1, inplace=True)\n",
    "replace_map = { 'season' : {'spring': 1, 'summer': 2, 'autumn': 3, 'winter' : 4}}\n",
    "test_data6 = test_data6.replace(replace_map)\n",
    "test_data6['season'] = test_data6['season'].astype(int)\n",
    "\n",
    "test_season = test_data6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_season\n",
    "df_test = test_data6\n",
    "\n",
    "train_data_x = df.drop('incidents', axis=1)\n",
    "train_label_y = df['incidents']\n",
    "test_data_x = df_test\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"dataset2.csv\", header=None, index=None, sep=';', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = data9.corr()\n",
    "sns.heatmap(corr_matrix, annot=False)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dt = clf.predict(X_test)\n",
    "predictions_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace_map = {'incidents' : {'None': 0, 'Low': 1, 'Medium': 2, 'High': 3, 'Very_High':4}}\n",
    "\n",
    "outcome = []\n",
    "for i in range(len(predictions_dt)):\n",
    "    if predictions_dt[i] == 0:\n",
    "        outcome.append({'RowId' : i+1 , 'Incidents' : 'None'})\n",
    "    elif predictions_dt[i] == 1:\n",
    "        outcome.append({'RowId' : i+1 , 'Incidents' : 'Low'})\n",
    "    elif predictions_dt[i] == 2:\n",
    "        outcome.append({'RowId' : i+1 , 'Incidents' : 'Medium'})\n",
    "    elif predictions_dt[i] == 3:\n",
    "        outcome.append({'RowId' : i+1 , 'Incidents' : 'High'})\n",
    "    elif predictions_dt[i] == 4:\n",
    "        outcome.append({'RowId' : i+1 , 'Incidents' : 'Very_High'})\n",
    "    \n",
    "print(outcome)\n",
    "od = pd.DataFrame(outcome)\n",
    "od.to_csv(\"out_file.csv\", index=False,header=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = data9\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_Test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "n_estimators = [200, 250]\n",
    "max_features = ['auto', 'sqrt',None]\n",
    "max_depth = [10,15,18]\n",
    "min_samples_split = [1,2]\n",
    "min_samples_leaf = [1,2]\n",
    "bootstrap = [True, False]\n",
    "criterion = ['entropy']\n",
    "\n",
    "\n",
    "param_grid = {'n_estimators' : n_estimators, \n",
    "              'max_features' : max_features,\n",
    "              'max_depth' : max_depth,\n",
    "              'min_samples_split' : min_samples_split,\n",
    "              'min_samples_leaf' : min_samples_leaf,\n",
    "              'bootstrap' : bootstrap,\n",
    "              'criterion' : criterion}\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "#rf.fit(X_train, y_train)\n",
    "\n",
    "#predictions = rf.predict(X_Test)\n",
    "#predictions\n",
    "\n",
    "#from sklearn.metrics import accuracy_score\n",
    "#rf.score(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "rf_GridSearch = GridSearchCV(estimator = rf , param_grid = param_grid, cv = 10, verbose = 2 , n_jobs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_GridSearch = rf_GridSearch.fit(train_data_x, train_label_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_GridSearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf_GridSearch.predict(test_data_x)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf_GridSearch.predict(X_train)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f'Train Accuracy - : {rf_GridSearch.score(X_train,y_train):.3f}')\n",
    "print (f'Test Accuracy - : {rf_GridSearch.score(X_Test,y_test):.3f}')#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = []\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] == 0:\n",
    "        outcome.append({'RowId' : i+1 , 'Incidents' : 'None'})\n",
    "    elif predictions[i] == 1:\n",
    "        outcome.append({'RowId' : i+1 , 'Incidents' : 'Low'})\n",
    "    elif predictions[i] == 2:\n",
    "        outcome.append({'RowId' : i+1 , 'Incidents' : 'Medium'})\n",
    "    elif predictions[i] == 3:\n",
    "        outcome.append({'RowId' : i+1 , 'Incidents' : 'High'})\n",
    "    elif predictions[i] == 4:\n",
    "        outcome.append({'RowId' : i+1 , 'Incidents' : 'Very_High'})\n",
    "    \n",
    "print(outcome)\n",
    "od = pd.DataFrame(outcome)\n",
    "od.to_csv(\"random_forest_grid_search_out.csv\", index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Oct 13 2022, 21:13:48) [GCC 12.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
